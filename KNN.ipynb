{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Nearest Neighbors Regressor (KNN)\n",
    "\n",
    "In this notebook, I use the K-Nearest Neighbors (KNN) algorithm to predict house prices for the Kaggle Housing Prices competition. KNN is a straightforward, instance-based learning method that makes predictions based on the similarity between data points.\n",
    "\n",
    "## How it works in this project:\n",
    "For each house in the test set, the algorithm finds the 'k' most similar houses in the training set, based on their features (such as size, location, and number of rooms).\n",
    "The predicted price is calculated as the average price of these 'k' nearest neighbors.\n",
    "The value of 'k' is a key parameter and is chosen based on model performance.\n",
    "\n",
    "## Why KNN?\n",
    "KNN does not make strong assumptions about the underlying data distribution, making it flexible for various types of data.\n",
    "It is easy to implement and interpret, providing a good baseline for regression tasks like house price prediction.\n",
    "Important notes for this notebook:\n",
    "Since KNN relies on distance calculations, all features are scaled to ensure fair comparison.\n",
    "The modelâ€™s performance is evaluated using cross-validation to select the optimal value of 'k'.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mimpute\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SimpleImputer\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# training data:\n",
    "train_raw = pd.read_csv('data/train.csv')\n",
    "test_raw = pd.read_csv('data/test.csv')\n",
    "\n",
    "print(\"Train data shape: \", train_raw.shape)\n",
    "print(\"Test data shape: \", test_raw.shape)\n",
    "print(train_raw.head())\n",
    "\n",
    "# get features and targets:\n",
    "X_train = train_raw.drop(['SalePrice', 'Id'], axis=1)  # I think that only Id needs to be dropped before PCA\n",
    "y_train = train_raw[\"SalePrice\"]\n",
    "X_test = test_raw.copy()  # can just copy as test.csv doesn't have the target\n",
    "\n",
    "# separate numerical and categorical features:\n",
    "numFeatures = X_train.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "catFeatures = X_train.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "# utilize pipelines for preprocessing:\n",
    "\n",
    "numPipeline = Pipeline([('imputer', SimpleImputer(strategy='median')),\n",
    "                        ('scaler', StandardScaler())])\n",
    "\n",
    "catPipeline = Pipeline([('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "                        ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))])\n",
    "\n",
    "# combine workflows:\n",
    "preprocessor = ColumnTransformer([('numerical', numPipeline, numFeatures),\n",
    "                                  ('categorical', catPipeline, catFeatures)])\n",
    "\n",
    "# now, fit and transform data:\n",
    "\n",
    "# use preprocessor to process train and test data:\n",
    "X_train_processed = preprocessor.fit_transform(X_train)\n",
    "X_test_processed = preprocessor.transform(X_test)\n",
    "\n",
    "# convert to pd dataframes:\n",
    "\n",
    "# need to concatenate processed numerical and categorical features:\n",
    "numFeature_names = numFeatures\n",
    "catFeature_names = preprocessor.named_transformers_['categorical'].named_steps['onehot'].get_feature_names_out(catFeatures)\n",
    "\n",
    "# concatenate\n",
    "totalFeatures = np.concatenate((numFeature_names, catFeature_names))\n",
    "\n",
    "# convert to dataframes:\n",
    "X_train_processed = pd.DataFrame(X_train_processed, columns=totalFeatures)\n",
    "X_test_processed = pd.DataFrame(X_test_processed, columns=totalFeatures)\n",
    "\n",
    "print(\"Processed Train dataset: \", X_train_processed.shape)\n",
    "print(\"Processed Test dataset: \", X_test_processed.shape)\n",
    "print(X_train_processed.head())\n",
    "\n",
    "# write out preprocessed data:\n",
    "X_train_processed.to_csv('data/train_processed.csv', index=False)\n",
    "X_test_processed.to_csv('data/test_processed.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
